use std::{
    future::Future,
    pin::Pin,
    sync::{
        atomic::{AtomicBool, Ordering},
        Arc,
    },
    task::{Context, Poll},
    time::Duration,
};

use futures::{FutureExt, StreamExt};
use instant::Instant;
use nimiq_block::Block;
use nimiq_blockchain_interface::AbstractBlockchain;
use nimiq_blockchain_proxy::BlockchainProxy;
use nimiq_hash::Blake2bHash;
use nimiq_network_interface::{network::Network, request::request_handler};
use nimiq_primitives::task_executor::TaskExecutor;
use nimiq_zkp_component::zkp_component::ZKPComponentProxy;
use tokio::sync::{
    broadcast::{channel as broadcast, Sender as BroadcastSender},
    mpsc::{
        channel as mpsc_channel, error::SendError, Receiver as MpscReceiver, Sender as MpscSender,
    },
    oneshot::{error::RecvError, Sender as OneshotSender},
};
#[cfg(not(target_family = "wasm"))]
use tokio::time::{sleep, Sleep};
use tokio_stream::wrappers::BroadcastStream;

use self::consensus_proxy::ConsensusProxy;
#[cfg(feature = "full")]
use self::remote_event_dispatcher::RemoteEventDispatcher;
use crate::{
    consensus::head_requests::{HeadRequests, HeadRequestsResult},
    messages::{RequestBlock, RequestHead, RequestMacroChain, RequestMissingBlocks},
    sync::{syncer::LiveSyncPushEvent, syncer_proxy::SyncerProxy},
};
#[cfg(feature = "full")]
use crate::{
    messages::{
        RequestBatchSet, RequestBlocksProof, RequestHistoryChunk,
        RequestTransactionReceiptsByAddress, RequestTransactionsProof, RequestTrieProof,
    },
    sync::live::{diff_queue::RequestTrieDiff, state_queue::RequestChunk},
};

pub mod consensus_proxy;
mod head_requests;
mod remote_data_store;
#[cfg(feature = "full")]
mod remote_event_dispatcher;

/// Events that are generated by the consensus component to convey the two possible states of consensus:
/// Established consensus (by satisfying some specific consensus criteria), or we lost it
#[derive(Clone)]
pub enum ConsensusEvent {
    /// Consensus is established
    Established,
    /// Consensus was lost
    Lost,
}

/// This enum is used to represent different kinds of events that are generated by other peers.
/// This is used for cases where we want to subscribe to other peers to receive notifications about those events.
/// For instance: we might be interested in knowing about transactions, from some specific address, that are included in a block
#[derive(Clone)]
pub enum RemoteEvent {
    /// Interesting receipts: They belong to an address that is interesting to us
    /// We get a vector of (transaction_hash, block_number) tuples
    InterestingReceipts(Vec<(Blake2bHash, u32)>),
    /// Other events, generated by peers, that might be interesting to us
    Placeholder,
}

/// Different Errors for a failed ResolveBlockRequest.
#[derive(Debug)]
pub enum ResolveBlockError<N: Network> {
    ReceiveError(RecvError),
    SendError(SendError<ConsensusRequest<N>>),
}

/// Requests the consensus to resolve a given `block_hash` at a specific `block_height`.
/// Additionally the sender of a response channel is presented and a number of peers who are
/// well suited to provide the required data.
pub struct ResolveBlockRequest<N: Network> {
    /// Block number of the to be resolved block.
    block_number: u32,

    /// Block hash of the to be resolved block.
    block_hash: Blake2bHash,

    /// The id of the message referencing the block being requested here. These do include peers
    /// which should have knowledge of the block. They will be used to resolve the block.
    pubsub_id: N::PubsubId,

    /// Sender to a oneshot channel where the response to the request is being awaited.
    response_sender: OneshotSender<Result<Block, ResolveBlockError<N>>>,
}

/// Enumeration of all ConsensusRequests available.
pub enum ConsensusRequest<N: Network> {
    ResolveBlock(ResolveBlockRequest<N>),
}

pub struct Consensus<N: Network> {
    pub blockchain: BlockchainProxy,
    pub network: Arc<N>,

    pub sync: SyncerProxy<N>,

    /// A Delay which exists purely for the waker on its poll to reactivate the task running Consensus::poll
    /// FIXME Remove this
    #[cfg(not(target_family = "wasm"))]
    next_execution_timer: Option<Pin<Box<Sleep>>>,
    events: BroadcastSender<ConsensusEvent>,
    established_flag: Arc<AtomicBool>,
    head_requests: Option<HeadRequests<N>>,
    head_requests_time: Option<Instant>,

    min_peers: usize,

    /// Sender and Receiver of a consensus request channel used to relay requests from any source
    /// to the Consensus instance. Currently the only source is a ConsensusProxy instance, but
    /// the Consensus is not limited to it.
    ///
    /// Both the sender and receiver are stored such that the sender can be cloned as required,
    /// while the receiver is actually polled within the Consensus poll function.
    ///
    /// The consensus itself is chosen, even though for the initial single request a structure
    /// somewhere deeper down the call stack would be adequate, as other requests may require different
    /// structures. Putting it here seemed to be the most flexible.
    requests: (
        MpscSender<ConsensusRequest<N>>,
        MpscReceiver<ConsensusRequest<N>>,
    ),

    zkp_proxy: ZKPComponentProxy<N>,
}

impl<N: Network> Consensus<N> {
    /// Minimum number of peers for consensus to be established.
    const MIN_PEERS_ESTABLISHED: usize = 3;

    /// Minimum number of block announcements extending the chain for consensus to be established.
    const MIN_BLOCKS_ESTABLISHED: usize = 5;

    /// Timeout after which head requests will be performed (again) to determine consensus
    /// established state and to advance the chain.
    const HEAD_REQUESTS_TIMEOUT: Duration = Duration::from_secs(5);

    /// Timeout after which the consensus is polled after it ran last
    ///
    /// TODO: Set appropriate duration
    /// FIXME Remove this
    #[cfg(not(target_family = "wasm"))]
    const CONSENSUS_POLL_TIMER: Duration = Duration::from_secs(1);

    pub fn from_network(
        blockchain: BlockchainProxy,
        network: Arc<N>,
        syncer: SyncerProxy<N>,
        zkp_proxy: ZKPComponentProxy<N>,
    ) -> Self {
        Self::new(
            blockchain,
            network,
            syncer,
            Self::MIN_PEERS_ESTABLISHED,
            zkp_proxy,
            Box::new(|fut| {
                tokio::spawn(fut);
            }),
        )
    }

    pub fn new(
        blockchain: BlockchainProxy,
        network: Arc<N>,
        syncer: SyncerProxy<N>,
        min_peers: usize,
        zkp_proxy: ZKPComponentProxy<N>,
        executor: impl TaskExecutor + Send + 'static,
    ) -> Self {
        let (tx, _rx) = broadcast(256);

        Self::init_network_request_receivers(&network, &blockchain, executor);

        #[cfg(feature = "full")]
        Self::init_remote_event_dispatcher(&network, &blockchain);

        let established_flag = Arc::new(AtomicBool::new(false));

        #[cfg(not(target_family = "wasm"))]
        let timer = Box::pin(sleep(Self::CONSENSUS_POLL_TIMER));

        Consensus {
            blockchain,
            network,
            sync: syncer,
            events: tx,
            #[cfg(not(target_family = "wasm"))]
            next_execution_timer: Some(timer),
            established_flag,
            head_requests: None,
            head_requests_time: None,
            min_peers,
            // Choose a small buffer as having a lot of items buffered here indicates a bigger problem.
            requests: mpsc_channel(10),
            zkp_proxy,
        }
    }

    fn init_remote_event_dispatcher(network: &Arc<N>, blockchain: &BlockchainProxy) {
        // We spawn the Remote Event Dispatcher into its own task (this is only available for full nodes and history nodes)

        match blockchain {
            #[cfg(feature = "full")]
            BlockchainProxy::Full(blockchain) => {
                let network = Arc::clone(network);
                let blockchain = Arc::clone(blockchain);
                let remote_event_dispatcher = RemoteEventDispatcher::new(network, blockchain);

                tokio::spawn(remote_event_dispatcher);
            }
            BlockchainProxy::Light(_) => {
                // The light blockchain does not provide this functionality
            }
        }
    }

    fn init_network_request_receivers(
        network: &Arc<N>,
        blockchain: &BlockchainProxy,
        executor: impl TaskExecutor + Send + 'static,
    ) {
        let stream = network.receive_requests::<RequestMacroChain>();
        executor.exec(Box::pin(request_handler(network, stream, blockchain)));

        let stream = network.receive_requests::<RequestBlock>();
        executor.exec(Box::pin(request_handler(network, stream, blockchain)));

        let stream = network.receive_requests::<RequestMissingBlocks>();
        executor.exec(Box::pin(request_handler(network, stream, blockchain)));

        let stream = network.receive_requests::<RequestHead>();
        executor.exec(Box::pin(request_handler(network, stream, blockchain)));
        match blockchain {
            #[cfg(feature = "full")]
            BlockchainProxy::Full(blockchain) => {
                let stream = network.receive_requests::<RequestBatchSet>();
                executor.exec(Box::pin(request_handler(network, stream, blockchain)));

                let stream = network.receive_requests::<RequestHistoryChunk>();
                executor.exec(Box::pin(request_handler(network, stream, blockchain)));

                let stream = network.receive_requests::<RequestTrieDiff>();
                executor.exec(Box::pin(request_handler(network, stream, blockchain)));

                let stream = network.receive_requests::<RequestChunk>();
                executor.exec(Box::pin(request_handler(network, stream, blockchain)));

                let stream = network.receive_requests::<RequestTransactionsProof>();
                executor.exec(Box::pin(request_handler(network, stream, blockchain)));

                let stream = network.receive_requests::<RequestTransactionReceiptsByAddress>();
                executor.exec(Box::pin(request_handler(network, stream, blockchain)));

                let stream = network.receive_requests::<RequestTrieProof>();
                executor.exec(Box::pin(request_handler(network, stream, blockchain)));

                let stream = network.receive_requests::<RequestBlocksProof>();
                executor.exec(Box::pin(request_handler(network, stream, blockchain)));
            }
            BlockchainProxy::Light(_) => {}
        }
    }

    pub fn subscribe_events(&self) -> BroadcastStream<ConsensusEvent> {
        BroadcastStream::new(self.events.subscribe())
    }

    pub fn is_established(&self) -> bool {
        self.established_flag.load(Ordering::Acquire)
    }

    pub fn num_agents(&self) -> usize {
        self.sync.num_peers()
    }

    pub fn proxy(&self) -> ConsensusProxy<N> {
        ConsensusProxy {
            blockchain: self.blockchain.clone(),
            network: Arc::clone(&self.network),
            established_flag: Arc::clone(&self.established_flag),
            events: self.events.clone(),
            request: self.requests.0.clone(),
        }
    }

    /// Forcefully sets consensus established, should be used for tests only.
    pub fn force_established(&mut self) {
        trace!("Consensus forcefully established.");
        self.established_flag.swap(true, Ordering::Release);

        // Also stop any other checks.
        self.head_requests = None;
        self.head_requests_time = None;

        // We don't care if anyone is listening.
        self.events.send(ConsensusEvent::Established).ok();
    }

    /// Calculates and sets established state, returns a ConsensusEvent if the state changed.
    /// Once consensus is established, we can only lose it if we lose all our peers.
    /// To reach consensus established state, we need at least `minPeers` peers and
    /// one of the following conditions must be true:
    /// - we accepted at least `MIN_BLOCKS_ESTABLISHED` block announcements
    /// - we know at least 2/3 of the head blocks of our peers
    ///
    /// The latter check is started immediately once we reach the minimum number of peers
    /// and is potentially repeated in an interval of `HEAD_REQUESTS_TIMEOUT` until one
    /// of the conditions above is true.
    /// Any unknown blocks resulting of the head check are handled similarly as block announcements
    /// via the block queue.
    fn check_established(
        &mut self,
        finished_head_request: Option<HeadRequestsResult<N>>,
    ) -> Option<ConsensusEvent> {
        // We can only lose established state right now if we drop below our minimum peer threshold.
        if self.is_established() {
            if self.num_agents() < self.min_peers {
                warn!("Lost consensus!");
                self.established_flag.swap(false, Ordering::Release);
                return Some(ConsensusEvent::Lost);
            }
        } else {
            // We have three conditions on whether we move to the established state.
            // First, we always need a minimum number of peers connected.
            // Second, the state must always be complete.
            // Then, we check that we either:
            // - accepted a minimum number of block announcements, or
            // - know the head state of a majority of our peers
            if self.num_agents() >= self.min_peers && self.sync.state_complete() {
                if self.sync.accepted_block_announcements() >= Self::MIN_BLOCKS_ESTABLISHED {
                    info!("Consensus established, number of accepted announcements satisfied.");
                    self.established_flag.swap(true, Ordering::Release);

                    // Also stop any other checks.
                    self.head_requests = None;
                    self.head_requests_time = None;
                    self.zkp_proxy
                        .request_zkp_from_peers(self.sync.peers(), false);
                    return Some(ConsensusEvent::Established);
                } else {
                    // The head state check is carried out immediately after we reach the minimum
                    // number of peers and then after certain time intervals until consensus is reached.
                    // If we have a finished one, check its outcome.
                    if let Some(head_request) = finished_head_request {
                        debug!("Trying to establish consensus, checking head request ({} known, {} unknown).", head_request.num_known_blocks, head_request.num_unknown_blocks);
                        // We would like that 2/3 of our peers have a known state.
                        if head_request.num_known_blocks >= 2 * head_request.num_unknown_blocks {
                            info!("Consensus established, 2/3 of heads known.");
                            self.established_flag.swap(true, Ordering::Release);
                            self.zkp_proxy
                                .request_zkp_from_peers(self.sync.peers(), false);
                            return Some(ConsensusEvent::Established);
                        }
                    }
                    // If there's no ongoing head request, check whether we should start a new one.
                    self.request_heads();
                }
            }
        }
        None
    }

    /// Requests heads from connected peers in a predefined interval.
    fn request_heads(&mut self) {
        // If there's no ongoing head request and we have at least one peer, check whether we should
        // start a new one.
        if self.head_requests.is_none() && (self.num_agents() > 0 || self.min_peers == 0) {
            // This is the case if `head_requests_time` is unset or the timeout is hit.
            let should_start_request = self
                .head_requests_time
                .map(|time| time.elapsed() >= Self::HEAD_REQUESTS_TIMEOUT)
                .unwrap_or(true);
            if should_start_request {
                debug!(
                    "Initiating head requests (to {} peers)",
                    self.sync.num_peers()
                );
                self.head_requests = Some(HeadRequests::new(
                    self.sync.peers(),
                    Arc::clone(&self.network),
                    self.blockchain.clone(),
                ));
                self.head_requests_time = Some(Instant::now());
            }
        }
    }
}

impl<N: Network> Future for Consensus<N> {
    type Output = ();

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        // 1. Poll and advance block queue
        while let Poll::Ready(Some(event)) = self.sync.poll_next_unpin(cx) {
            match event {
                LiveSyncPushEvent::AcceptedAnnouncedBlock(_) => {
                    // Reset the head request timer when an announced block was accepted.
                    self.head_requests_time = Some(Instant::now());
                }
                LiveSyncPushEvent::AcceptedBufferedBlock(_, remaining_in_buffer) => {
                    if !self.is_established() {
                        // Note: this output is parsed by our testing infrastructure (specifically devnet.sh),
                        // so please test that nothing breaks in there if you change this.
                        let block_number = {
                            let blockchain = self.blockchain.read();
                            blockchain.block_number()
                        };

                        info!(
                            "Catching up to tip of the chain (now at #{}, {} blocks remaining)",
                            block_number, remaining_in_buffer
                        );

                        if remaining_in_buffer == 0 {
                            self.head_requests_time = None;
                        }
                    }
                }
                LiveSyncPushEvent::ReceivedMissingBlocks(_) => {
                    if !self.is_established() {
                        // When syncing a stopped chain, we want to immediately start a new head request
                        // after receiving blocks for the current epoch.
                        self.head_requests_time = None;
                    }
                }
                LiveSyncPushEvent::RejectedBlock(hash) => {
                    warn!("Rejected block {}", hash);
                }
                LiveSyncPushEvent::AcceptedChunks(_) => {}
            }
        }

        // Check consensus established state on changes.
        if let Some(event) = self.check_established(None) {
            self.events.send(event).ok();
        }

        // 2. Poll any head requests if active.
        if let Some(ref mut head_requests) = self.head_requests {
            if let Poll::Ready(mut result) = head_requests.poll_unpin(cx) {
                // Reset head requests.
                self.head_requests = None;

                // Push unknown blocks to the block queue, trying to sync.
                for (block, peer_id) in result.unknown_blocks.drain(..) {
                    self.sync.push_block(block, peer_id, None);
                }

                // Update established state using the result.
                if let Some(event) = self.check_established(Some(result)) {
                    self.events.send(event).ok();
                }
            }
        }

        // 3. Check if a ConsensusRequest was received
        while let Poll::Ready(Some(request)) = self.requests.1.poll_recv(cx) {
            match request {
                ConsensusRequest::ResolveBlock(_resolve_block) => {}
            }
        }

        // 4. Update timer and poll it so the task gets woken when the timer runs out (at the latest)
        // The timer itself running out (producing an Instant) is of no interest to the execution. This poll method
        // was potentially awoken by the delays waker, but even then all there is to do is set up a new timer such
        // that it will wake this task again after another time frame has elapsed. No interval was used as that
        // would periodically wake the task even though it might have just executed
        #[cfg(not(target_family = "wasm"))]
        {
            let mut timer = Box::pin(sleep(Self::CONSENSUS_POLL_TIMER));
            // If the sleep wasn't pending anymore, it didn't register us with the waker, but we need that.
            assert!(timer.poll_unpin(cx) == Poll::Pending);
            self.next_execution_timer = Some(timer);
        }

        // 5. Advance consensus and catch-up through head requests.
        self.request_heads();

        Poll::Pending
    }
}
